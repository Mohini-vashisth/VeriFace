{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.17.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (4.10.0.84)\n",
      "Requirement already satisfied: librosa in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.10.2.post1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.66.5)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.9.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (4.45.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/lakshya/Library/Python/3.12/lib/python/site-packages (from tensorflow->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/lakshya/Library/Python/3.12/lib/python/site-packages (from tensorflow->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/lakshya/Library/Python/3.12/lib/python/site-packages (from librosa->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/lakshya/Library/Python/3.12/lib/python/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (0.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (0.20.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 1)) (0.44.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 7)) (2024.9.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 1)) (13.8.1)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 4)) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/lakshya/Library/Python/3.12/lib/python/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 4)) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 4)) (1.17.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 4)) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/lakshya/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 1)) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow->-r requirements.txt (line 1)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lakshya/Library/Python/3.12/lib/python/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow.keras (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow.keras\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install tensorflow.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Loading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aagfhgtpmv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'vudstovrck.mp4'}, 'aapnvogymq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jdubbvfswz.mp4'}, 'abarnvbtwb.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'abofeumbvv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}, 'abqwwspghj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qzimuostzz.mp4'}, 'acifjvzvpm.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kbvibjhfzo.mp4'}, 'acqfdwsrhi.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ccfoszqabv.mp4'}, 'acxnxvbsxk.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fjlyaizcwc.mp4'}, 'acxwigylke.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ffcwhpnpuw.mp4'}, 'aczrgyricp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'slwkmefgde.mp4'}, 'adhsbajydo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}, 'adohikbdaz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qjlhemtkxk.mp4'}, 'adylbeequz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dlpoieqvfb.mp4'}, 'aelfnikyqj.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'aelzhcnwgf.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qzimuostzz.mp4'}, 'aettqgevhz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'proiippuup.mp4'}, 'aevrfsexku.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gxembgiarp.mp4'}, 'afoovlsmtx.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'agdkmztvby.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iufotyxgzb.mp4'}, 'agqphdxmwt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'aytzyidmgs.mp4'}, 'agrmhtjdlk.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ahbweevwpv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dkuayagnmc.mp4'}, 'ahdbuwqxit.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jomvcqqars.mp4'}, 'ahfazfbntc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'sunqwnmlkx.mp4'}, 'ahqqqilsxt.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'aipfdnwpoo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ygdgwyqyut.mp4'}, 'ajqslcypsw.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ajwpjhrbcv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bzythlfnhq.mp4'}, 'aklqzsddfl.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'lyvlnqduqg.mp4'}, 'aknbdpmgua.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yxyhvdlrgk.mp4'}, 'aknmpoonls.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'swedbyuehz.mp4'}, 'akvmwkdyuv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xlbnmndmku.mp4'}, 'akxoopqjqz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}, 'akzbnazxtz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ppdpgwyjgm.mp4'}, 'aladcziidp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fewcljwqkr.mp4'}, 'alaijyygdv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cppdvdejkc.mp4'}, 'alninxcyhg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tqhbgzfwsf.mp4'}, 'altziddtxi.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}, 'alvgwypubw.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'vcxckqbaya.mp4'}, 'amaivqofda.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xobhsemxmv.mp4'}, 'amowujxmzc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xwcggrygwl.mp4'}, 'andaxzscny.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}, 'aneclqfpbt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xxsxktyvzt.mp4'}, 'anpuvshzoo.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'aorjvbyxhw.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bulkxhhknf.mp4'}, 'apatcsqejh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'edyncaijwx.mp4'}, 'apgjqzkoma.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jkddywriuf.mp4'}, 'apogckdfrz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'uonshkejav.mp4'}, 'aqpnvjhuzw.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}, 'arkroixhey.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fjlyaizcwc.mp4'}, 'arlmiizoob.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}, 'arrhsnjqku.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'inkqxytzyu.mp4'}, 'asaxgevnnp.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'asdpeebotb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'znjupdqnwo.mp4'}, 'aslsvlvpth.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jepguaulgf.mp4'}, 'asmpfjfzif.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}, 'asvcrfdpnq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'upgerjvcjb.mp4'}, 'atkdltyyen.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'atvmxvwyns.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'atxvxouljq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'wwqiuiwdbz.mp4'}, 'atyntldecu.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mfzqxktxud.mp4'}, 'atzdznmder.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qedsgieuqn.mp4'}, 'aufmsmnoye.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ppdpgwyjgm.mp4'}, 'augtsuxpzc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ifbdbogiqn.mp4'}, 'avfitoutyn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mfzqxktxud.mp4'}, 'avgiuextiz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'hyhjfdxqxy.mp4'}, 'avibnnhwhp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jdubbvfswz.mp4'}, 'avmjormvsx.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'avnqydkqjj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'efwfxwwlbw.mp4'}, 'avssvvsdhz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gktjowiuqe.mp4'}, 'avtycwsgyb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}, 'avvdgsennp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}, 'avywawptfc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rrcsuwgpnd.mp4'}, 'awhmfnnjih.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xclqbefnvc.mp4'}, 'awnwkrqibf.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cprhtltsjp.mp4'}, 'awukslzjra.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ujzwwfkeia.mp4'}, 'axczxisdtb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}, 'axntxmycwd.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'axoygtekut.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'topyiohccg.mp4'}, 'axwgcsyphv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mfnowqfdwl.mp4'}, 'axwovszumc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rvoudrbyac.mp4'}, 'aybgughjxh.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'aybumesmpk.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ayqvfdhslr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xxrzzncksa.mp4'}, 'aytzyidmgs.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'azpuxunqyo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jjyfvzxwwx.mp4'}, 'azsmewqghg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'djxdyjopjd.mp4'}, 'bahdpoesir.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xnhcreiyqg.mp4'}, 'bbhpvrmbse.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'imzqmbfugn.mp4'}, 'bbhtdfuqxq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cpjxareypw.mp4'}, 'bbvgxeczei.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}, 'bchnbulevv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iyefnuagav.mp4'}, 'bctvsmddgq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ybjrqnqnno.mp4'}, 'bdbhekrrwo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}, 'bddjdhzfze.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bdgipnyobr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'keecvpbncd.mp4'}, 'bdnaqemxmr.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bdxuhamuqx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fecysfujzk.mp4'}, 'beboztfcme.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bejhvclboh.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'benmsfzfaz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kysxawkest.mp4'}, 'beyebyhrph.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bffwsjxghk.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bgaogsjehq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xzvrgckqkz.mp4'}, 'bggsurpgpr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gxembgiarp.mp4'}, 'bghphrsfxf.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'sgjnvxvcpu.mp4'}, 'bgmlwsoamc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'woshnzbxmc.mp4'}, 'bguwlyazau.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'znpdbbsfvj.mp4'}, 'bgvhtpzknn.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bgwmmujlmc.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bhaaboftbc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rlvgtsjyer.mp4'}, 'bhbdugnurr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'vcxckqbaya.mp4'}, 'bhpwpydzpo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yfsnwkbafm.mp4'}, 'bhsluedavd.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kydlpqfrvv.mp4'}, 'bilnggbxgu.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bjjbwsqjir.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tdohqkzvbk.mp4'}, 'bjkmjilrxp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yfsnwkbafm.mp4'}, 'bjsmaqefoi.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mfpgdgsaxg.mp4'}, 'bkmdzhfzfh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'hyuipchisa.mp4'}, 'bkvetcojbt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ybjrqnqnno.mp4'}, 'bkwxhglwct.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}, 'blpchvmhxx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xqnykluhws.mp4'}, 'blzydqdfem.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dbtbbhakdv.mp4'}, 'bmbbkwmxqj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rrcsuwgpnd.mp4'}, 'bmehkyanbj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ptokilxwcx.mp4'}, 'bmhvktyiwp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gneufaypol.mp4'}, 'bmioepcpsx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'vmospzljws.mp4'}, 'bmjmjmbglm.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mmhqllmlew.mp4'}, 'bmjzrlszhi.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bnbuonyoje.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fntskqfxxf.mp4'}, 'bndybcqhfr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xnfwdpptym.mp4'}, 'bnjcdrfuov.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ellavthztb.mp4'}, 'bntlodcfeg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ytufbmkdlq.mp4'}, 'bofqajtwve.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dbtbbhakdv.mp4'}, 'boovltmuwi.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'sfujxhuyje.mp4'}, 'bopqhhalml.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'oesxbvktem.mp4'}, 'bourlmzsio.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bxzakyopjf.mp4'}, 'bpapbctoao.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bpwzipqtxf.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'lmlyvmfbbe.mp4'}, 'bpxckdzddv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cizlkenljw.mp4'}, 'bqdjzqhcft.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ytufbmkdlq.mp4'}, 'bqeiblbxtl.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iklzfeueid.mp4'}, 'bqhtpqmmqp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}, 'bqkdbcqjvb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}, 'bqnymlsayl.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xagsvjctmp.mp4'}, 'bqqpbzjgup.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'djxdyjopjd.mp4'}, 'bqtuuwzdtr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yagllixjvh.mp4'}, 'brhalypwoo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'uuxqylnzls.mp4'}, 'brvqtabyxj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}, 'brwrlczjvi.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bseamdrpbj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fdcttsvjwf.mp4'}, 'bsfmwclnqy.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ubplsigbvj.mp4'}, 'bsqgziaylx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'brwrlczjvi.mp4'}, 'btiysiskpf.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gxhcuxulhi.mp4'}, 'btjlfpzbdu.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'drcyabprvt.mp4'}, 'btjwbtsgln.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xwcggrygwl.mp4'}, 'btmsngnqhv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'crezycjqyk.mp4'}, 'btohlidmru.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cyxlcuyznd.mp4'}, 'btugrnoton.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}, 'btunxncpjh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mgowkzsbyx.mp4'}, 'btxlttbpkj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fhghkqdkhe.mp4'}, 'bulkxhhknf.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bvgwelbeof.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mmhqllmlew.mp4'}, 'bvzjkezkms.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ekcrtigpab.mp4'}, 'bweezhfpzp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}, 'bwhlgysghg.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bwipwzzxxu.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bwuwstvsbw.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xzvrgckqkz.mp4'}, 'bxzakyopjf.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'bydaidkpdp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gktjowiuqe.mp4'}, 'byfenovjnf.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}, 'byijojkdba.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'liniegczcx.mp4'}, 'byofowlkki.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ifjktxxiln.mp4'}, 'byqzyxifza.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}, 'byunigvnay.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'nvpluswotp.mp4'}, 'byyqectxqa.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fdcttsvjwf.mp4'}, 'bzmdrafeex.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'sqwvfgwdxr.mp4'}, 'bzythlfnhq.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'caifxvsozs.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'caqbrkogkb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'vgqotmftcr.mp4'}, 'cbbibzcoih.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'lietldeotq.mp4'}, 'cbltdtxglo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'svcnlasmeh.mp4'}, 'ccfoszqabv.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ccmonzqfrz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gxhcuxulhi.mp4'}, 'cdaxixbosp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'itzmdwutdu.mp4'}, 'cdbsbdymzd.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}, 'cdphtzqrvp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ehtdtkmmli.mp4'}, 'cdyakrxkia.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}, 'cepxysienc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'euqpvnyxrb.mp4'}, 'cettndmvzl.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kysxawkest.mp4'}, 'ceymbecxnj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}, 'cferslmfwh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fygviyzcjm.mp4'}, 'cffffbcywc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ztbinwxgyu.mp4'}, 'cfxkpiweqt.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cfyduhpbps.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tfoxelmnjx.mp4'}, 'cglxirfaey.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qypgyrxcme.mp4'}, 'cgvrgibpfo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'puppdcffcj.mp4'}, 'chtapglbcj.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'chviwxsfhg.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'chzieimrwu.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'topyiohccg.mp4'}, 'ciyoudyhly.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cizlkenljw.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ckbdwedgmc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'zrkinjhsuq.mp4'}, 'ckjaibzfxa.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ckkuyewywx.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cknyxaqouy.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bwipwzzxxu.mp4'}, 'cksanfsjhc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'atkdltyyen.mp4'}, 'clihsshdkq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qzimuostzz.mp4'}, 'clrycekyst.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cmbzllswnl.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cmxcfkrjiv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ztbinwxgyu.mp4'}, 'cnilkgvfei.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kwyvikrgmx.mp4'}, 'coadfnerlk.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bwipwzzxxu.mp4'}, 'cobjrlugvp.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'covdcysmbi.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jomvcqqars.mp4'}, 'cpjxareypw.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cppdvdejkc.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cprhtltsjp.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'cqfugiqupm.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fpvduejzcw.mp4'}, 'cqhngvpgyi.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tfoixxmpoo.mp4'}, 'cqrskwiqng.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'swedbyuehz.mp4'}, 'crezycjqyk.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'crktehraph.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'vrsinxahfh.mp4'}, 'crzfebnfgb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'wgmbcqfgkp.mp4'}, 'cthdnahrkh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'vrsinxahfh.mp4'}, 'ctpqeykqdp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iklzfeueid.mp4'}, 'cttqtsjvgn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fkyrrigzpt.mp4'}, 'ctzmavwror.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'lkdlzpkukw.mp4'}, 'curpwogllm.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'chtapglbcj.mp4'}, 'cuzrgrbvil.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iiomvouemm.mp4'}, 'cvaksbpssm.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gdfyzwykty.mp4'}, 'cwbacdwrzo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fecysfujzk.mp4'}, 'cwqlvzefpg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}, 'cwrtyzndpx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}, 'cwsbspfzck.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'wtreibcmgm.mp4'}, 'cwwandrkus.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}, 'cxfujlvsuw.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}, 'cxrfacemmq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dlpoieqvfb.mp4'}, 'cxttmymlbn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qapnbtdypb.mp4'}, 'cyboodqqyr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}, 'cycacemkmt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}, 'cyclgfjdrv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}, 'cyxlcuyznd.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'czfunozvwp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'caifxvsozs.mp4'}, 'czkdanyadc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}, 'czmqpxrqoh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}, 'dafhtipaml.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kdodrvufdh.mp4'}, 'dakiztgtnw.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dakqwktlbi.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}, 'dbhoxkblzx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}, 'dbhrpizyeq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ffcwhpnpuw.mp4'}, 'dbnygxtwek.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dboxtiehng.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jjyfvzxwwx.mp4'}, 'dbtbbhakdv.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dbzcqmxzaj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yxyhvdlrgk.mp4'}, 'dbzpcjntve.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ellavthztb.mp4'}, 'dcamvmuors.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iuzdfwsefw.mp4'}, 'dcuiiorugd.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'wapebjxejr.mp4'}, 'ddepeddixj.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ddhfabwpuz.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'luvasmspox.mp4'}, 'ddjggcasdw.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}, 'ddpvuimigj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ijokcwewbs.mp4'}, 'ddqccgmtka.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qokxxuayqn.mp4'}, 'degpbqvcay.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ptokilxwcx.mp4'}, 'deywhkarol.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ljaifbsfuw.mp4'}, 'deyyistcrd.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}, 'dfbpceeaox.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bffwsjxghk.mp4'}, 'dgmevclvzy.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jzmdganfys.mp4'}, 'dgxrqjdomn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'duycddgtrl.mp4'}, 'dgzklxjmix.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jszyyhamrh.mp4'}, 'dhcndnuwta.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dhcselezer.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'uonshkejav.mp4'}, 'dhevettufk.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cppdvdejkc.mp4'}, 'dhjmzhrcav.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tdohqkzvbk.mp4'}, 'dhkwmjxwrn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ehccixxzoe.mp4'}, 'dhoqofwoxa.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}, 'dhxctgyoqj.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'diomeixhrg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gneufaypol.mp4'}, 'diopzaywor.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fgfyrfyqay.mp4'}, 'diqraixiov.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gmihbscmwq.mp4'}, 'diuzrpqjli.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'smggzgxymo.mp4'}, 'djvtbgwdcc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jljpdojupu.mp4'}, 'djvutyvaio.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'zhfyuhonra.mp4'}, 'djxdyjopjd.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dkdwxmtpuo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'mmhqllmlew.mp4'}, 'dkhlttuvmx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}, 'dkrvorliqc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'hcswybumab.mp4'}, 'dkuayagnmc.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dkwjwbwgey.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rfzzrftgco.mp4'}, 'dkzvdrzcnr.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dlpoieqvfb.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dlrsbscitn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ztbinwxgyu.mp4'}, 'dnexlwbcxq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ezaajaswoe.mp4'}, 'dnhvalzvrt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tamayudqqx.mp4'}, 'dntkzzzcdh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gnyspcpbhd.mp4'}, 'dnyvfblxpm.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'eckvhdusax.mp4'}, 'doanjploai.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fkqptfouqw.mp4'}, 'dofusvhnib.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xnfwdpptym.mp4'}, 'dozyddhild.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ngdswpaqnt.mp4'}, 'dptbnjnkdg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kkzsnmrkqk.mp4'}, 'dptrzdvwpg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iiomvouemm.mp4'}, 'dqnyszdong.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}, 'dqppxmoqdl.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'zrkinjhsuq.mp4'}, 'dqqtjcryjv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iyefnuagav.mp4'}, 'dqswpjoepo.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kydlpqfrvv.mp4'}, 'dqzreruvje.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rlldzrnmdn.mp4'}, 'drcyabprvt.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'drgjzlxzxj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yagllixjvh.mp4'}, 'drsakwyvqv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jomvcqqars.mp4'}, 'drtbksnpol.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}, 'dsdoseflas.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}, 'dsgpbgsrdm.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'nlerwupaqr.mp4'}, 'dsjbknkujw.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dsndhujjjb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ohnonevlro.mp4'}, 'dtbpmdqvao.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}, 'dtocdfbwca.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dakiztgtnw.mp4'}, 'dubiroskqn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gzyzdcbuuv.mp4'}, 'dulanfulol.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iieoqptzec.mp4'}, 'duvyaxbzvp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fgfyrfyqay.mp4'}, 'duycddgtrl.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'duzuusuajr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fgfyrfyqay.mp4'}, 'dvakowbgbt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'slwkmefgde.mp4'}, 'dvumqqhoac.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kuelhabsmz.mp4'}, 'dwediigjit.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tmdformfqp.mp4'}, 'dxbqjxrhin.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'dxuliowugt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'imzqmbfugn.mp4'}, 'dxuplhwvig.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yoavqsqobz.mp4'}, 'dzieklokdr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'pylnolwenx.mp4'}, 'dzqwgqewhu.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xwcggrygwl.mp4'}, 'dzvyfiarrq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bgwmmujlmc.mp4'}, 'dzwkmcwkwl.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'pqvypayzrp.mp4'}, 'dzyuwjkjui.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'eahlqmfvtj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'lyvlnqduqg.mp4'}, 'eajlrktemq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'yjlsxqoauz.mp4'}, 'ebchwmwayp.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ehccixxzoe.mp4'}, 'ebebgmtlcu.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iufotyxgzb.mp4'}, 'ebeknhudxq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}, 'ebkzwjgjhq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}, 'ebywfrmhtd.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'grnycmbdfu.mp4'}, 'eckvhdusax.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ecnihjlfyt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kysxawkest.mp4'}, 'ecujsjhscd.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ecuvtoltue.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}, 'ecwaxgutkc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'itmwoyxbas.mp4'}, 'eczrseixwq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'iieoqptzec.mp4'}, 'edyncaijwx.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'eebrkicpry.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rjlgchzmfv.mp4'}, 'eebserckhh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}, 'eejswgycjc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}, 'eekozbeafq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'olakcrnuro.mp4'}, 'eepezmygaq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'abarnvbtwb.mp4'}, 'eeyhxisdfh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'lyvlnqduqg.mp4'}, 'efdyrflcpg.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}, 'efwfxwwlbw.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'egbbcxcuqy.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'hqtepxaeqx.mp4'}, 'eggbjzxnmg.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'egghxjjmfg.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ehbnclaukr.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}, 'ehccixxzoe.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ehdkmxgtxh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bejhvclboh.mp4'}, 'ehevsxtecd.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'nzquxipbye.mp4'}, 'ehfiekigla.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'avmjormvsx.mp4'}, 'ehieahnhte.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'sasoxcqisz.mp4'}, 'ehtdtkmmli.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'eiriyukqqy.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ixuouyigxa.mp4'}, 'eivxffliio.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'joeifeskbs.mp4'}, 'eiwopxzjfn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'xzvrgckqkz.mp4'}, 'eixwxvxbbn.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}, 'ejkqesyvam.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'jwcsqxzdlv.mp4'}, 'ekcrtigpab.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'ekhacizpah.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'egghxjjmfg.mp4'}, 'ekkdjkirzq.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'tivkmbqgwp.mp4'}, 'elginszwtk.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}, 'ellavthztb.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'elvvackpjh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qhkqqfznrg.mp4'}, 'emaalmsonj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}, 'emfbhytfhc.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cprhtltsjp.mp4'}, 'emgjphonqb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ybjrqnqnno.mp4'}, 'ensyyivobf.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'lulmevqtla.mp4'}, 'eoewqcpbgt.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}, 'eprybmbpba.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'kuelhabsmz.mp4'}, 'epymyyiblu.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'svcnlasmeh.mp4'}, 'eqjscdagiv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'dbnygxtwek.mp4'}, 'eqnoqyfquo.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'eqvuznuwsa.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'cmbzllswnl.mp4'}, 'erlvuvjsjf.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'erqgqacbqe.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'nvpluswotp.mp4'}, 'errocgcham.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'grnycmbdfu.mp4'}, 'esckbnkkvb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gdfyzwykty.mp4'}, 'esgftaficx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'rrcsuwgpnd.mp4'}, 'esnntzzajv.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'ybetenmsye.mp4'}, 'esxrvsgpvb.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gomwfvijiv.mp4'}, 'esyhwdfnxs.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}, 'esyrimvzsa.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}, 'etdcqxabww.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}, 'etejaapnxh.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'wtreibcmgm.mp4'}, 'etmcruaihe.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'afoovlsmtx.mp4'}, 'etohcvnzbj.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'bdnaqemxmr.mp4'}, 'eudeqjhdfd.mp4': {'label': 'REAL', 'split': 'train', 'original': None}, 'eukvucdetx.mp4': {'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_metadata(metadata_path):\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    return metadata\n",
    "\n",
    "\n",
    "metadata_path = \"/Users/lakshya/Desktop/Projects/VeriFace/Dataset/metadata.json\"\n",
    "metadata = load_metadata(metadata_path)\n",
    "print(metadata)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   3%|         | 13/401 [00:08<04:27,  1.45video/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m video_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/lakshya/Desktop/Projects/VeriFace/Dataset/Train Videos\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     73\u001b[0m metadata \u001b[38;5;241m=\u001b[39m load_metadata(metadata_path)\n\u001b[0;32m---> 75\u001b[0m videos, labels, additional_features \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_videos_with_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mprocess_videos_with_metadata\u001b[0;34m(video_dir, metadata, max_frames, target_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m video_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(video_file)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     51\u001b[0m video_metadata \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mget(video_id, {})\n\u001b[0;32m---> 53\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mload_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m videos\u001b[38;5;241m.\u001b[39mappend(frames)\n\u001b[1;32m     55\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(video_metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# Default to 0 if no label\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mload_video\u001b[0;34m(video_path, max_frames, target_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frames) \u001b[38;5;241m<\u001b[39m max_frames:\n\u001b[0;32m---> 11\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def load_video(video_path, max_frames=100, target_size=(224, 224)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened() and len(frames) < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = frame / 255.0  # Normalize frame values to [0, 1]\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # If the video has fewer frames than max_frames, pad it with black frames\n",
    "    while len(frames) < max_frames:\n",
    "        frames.append(np.zeros((target_size[0], target_size[1], 3)))  # Padding with black frames (RGB)\n",
    "    \n",
    "    return np.array(frames)\n",
    "\n",
    "def pad_sequences(sequences, maxlen=None, padding_value=0):\n",
    "    if maxlen is None:\n",
    "        maxlen = max(len(seq) for seq in sequences)\n",
    "    \n",
    "    padded_sequences = np.full((len(sequences), maxlen, *sequences[0].shape[1:]), padding_value)\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        padded_sequences[i, :len(seq)] = seq\n",
    "    \n",
    "    return padded_sequences\n",
    "\n",
    "def process_videos_with_metadata(video_dir, metadata, max_frames=100, target_size=(224, 224)):\n",
    "    videos = []\n",
    "    labels = []\n",
    "    additional_features = []\n",
    "\n",
    "    video_files = os.listdir(video_dir)\n",
    "\n",
    "    # Use tqdm to add a progress bar to the loop\n",
    "    for video_file in tqdm(video_files, desc=\"Processing videos\", unit=\"video\"):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        \n",
    "        # Extract metadata for the video\n",
    "        video_id = os.path.splitext(video_file)[0]\n",
    "        video_metadata = metadata.get(video_id, {})\n",
    "        \n",
    "        frames = load_video(video_path, max_frames, target_size)\n",
    "        videos.append(frames)\n",
    "        labels.append(video_metadata.get('label', 0))  # Default to 0 if no label\n",
    "        additional_features.append(video_metadata.get('features', {}))  # Adjust based on your metadata structure\n",
    "\n",
    "    # Pad all sequences to ensure they have the same shape\n",
    "    videos_padded = np.array(videos)  # Since padding was handled during loading, this is directly converted\n",
    "    \n",
    "    return videos_padded, np.array(labels), additional_features\n",
    "\n",
    "# Function to load metadata (assuming JSON-like structure)\n",
    "def load_metadata(metadata_path):\n",
    "    # Load metadata from a file (replace with actual loading logic)\n",
    "    import json\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    return metadata\n",
    "\n",
    "# Example usage\n",
    "video_dir = '/Users/lakshya/Desktop/Projects/VeriFace/Dataset/Train Videos'\n",
    "metadata = load_metadata(metadata_path)\n",
    "\n",
    "videos, labels, additional_features = process_videos_with_metadata(video_dir, metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Extraction*\n",
    "1. Video Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "def extract_frames(video_path, output_dir, frame_rate=1):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_rate == 0:\n",
    "            cv2.imwrite(os.path.join(output_dir, f\"frame_{count}.jpg\"), frame)\n",
    "        count += 1\n",
    "    cap.release()\n",
    "\n",
    "def process_videos(video_dir, output_base_dir, frame_rate=1):\n",
    "    if not os.path.exists(output_base_dir):\n",
    "        os.makedirs(output_base_dir)\n",
    "    \n",
    "    # Get all video files in the specified directory\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "    \n",
    "    # Limit to 400 videos\n",
    "    video_files = video_files[:400]\n",
    "    \n",
    "    # Use tqdm to show progress bar for the videos being processed\n",
    "    for video_file in tqdm(video_files, desc=\"Processing videos\", unit=\"video\"):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        output_dir = os.path.join(output_base_dir, os.path.splitext(video_file)[0])\n",
    "        extract_frames(video_path, output_dir, frame_rate)\n",
    "\n",
    "# Example usage\n",
    "process_videos(videos, 'Extracted Video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Audio Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def extract_audio(video_path, output_audio_path):\n",
    "    audio = AudioSegment.from_file(video_path, format=\"mp4\")\n",
    "    audio.export(output_audio_path, format=\"wav\")\n",
    "\n",
    "def process_audios(video_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Get all video files in the specified directory\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "    \n",
    "    # Limit to 400 videos\n",
    "    video_files = video_files[:400]\n",
    "    \n",
    "    # Initialize the progress bar\n",
    "    with tqdm(total=len(video_files), desc=\"Processing Videos\", unit=\"file\") as pbar:\n",
    "        for video_file in video_files:\n",
    "            video_path = os.path.join(video_dir, video_file)\n",
    "            output_audio_path = os.path.join(output_dir, os.path.splitext(video_file)[0] + '.wav')\n",
    "            extract_audio(video_path, output_audio_path)\n",
    "            \n",
    "            # Update the progress bar after processing each file\n",
    "            pbar.update(1)\n",
    "\n",
    "# Example usage\n",
    "process_audios(videos, 'Extracted Audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing*\n",
    "1. Video Preprocessing: Resizing, Normalizing, Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def preprocess_video_frame(frame, target_size=(224, 224)):\n",
    "    frame = tf.image.resize(frame, target_size)\n",
    "    frame = tf.cast(frame, tf.float32) / 255.0  # Normalize\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Audio Preprocessing: Resampling, Noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def preprocess_audio(audio_path, target_sr=16000):\n",
    "    y, sr = librosa.load(audio_path, sr=target_sr)\n",
    "    y = librosa.effects.trim(y)[0]  # Trim silence\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model Creation*\n",
    "1. Video Models: ResNet, VGG-16, C3D, TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "def create_resnet_model(input_shape=(224, 224, 3)):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax') \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "resnet_model = create_resnet_model()\n",
    "resnet_model.save('saved_model.keras')\n",
    "resnet_model = tf.keras.models.load_model('saved_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_vgg16_model(input_shape=(224, 224, 3), num_classes=10):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  \n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_c3d_model(input_shape=(16, 112, 112, 3), num_classes=10):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(layers.Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(layers.Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(layers.Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(layers.Conv3D(512, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv3D(512, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(layers.Conv3D(512, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv3D(512, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Feature Extraction - TCN using Conv2D for image input\n",
    "def create_tcn_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Audio Models: Wav2Vec, CRNN, VGGish, WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "# Load pre-trained Wav2Vec2.0 model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Load and preprocess audio\n",
    "def extract_wav2vec2_features(audio_path):\n",
    "    # Load audio file with librosa\n",
    "    y, sr = librosa.load(audio_path, sr=16000)  # Wav2Vec2 requires 16kHz sample rate\n",
    "    \n",
    "    # Preprocess the audio to match the input format for Wav2Vec2.0\n",
    "    input_values = processor(y, return_tensors=\"pt\", sampling_rate=sr).input_values\n",
    "    \n",
    "    # Extract features (output from the last hidden layer)\n",
    "    with torch.no_grad():\n",
    "        features = model(input_values).last_hidden_state\n",
    "    \n",
    "    return features\n",
    "\n",
    "wav2vec_features = extract_wav2vec2_features('Extracted Audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_mel_spectrogram(audio_path, n_mels=128):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "# CRNN model\n",
    "def create_crnn_model(input_shape=(128, 128, 1), num_classes=10):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # CNN layers\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # RNN layers (GRU or LSTM)\n",
    "    model.add(layers.Reshape(target_shape=(-1, 128)))\n",
    "    model.add(layers.GRU(128, return_sequences=False))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "# Load the VGGish model from TensorFlow Hub\n",
    "def load_vggish_model():\n",
    "    vggish_model = hub.load(\"https://tfhub.dev/google/vggish/1\")\n",
    "    return vggish_model\n",
    "\n",
    "# Preprocess the audio file to match VGGish input requirements (16kHz, mono)\n",
    "def preprocess_audio(audio_path):\n",
    "    # Load audio using soundfile and librosa\n",
    "    audio, sr = librosa.load(audio_path, sr=16000)  # Resample to 16kHz if not already\n",
    "    # VGGish expects mono audio (single channel), ensure it's mono\n",
    "    if len(audio.shape) > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    return audio\n",
    "\n",
    "# Extract features using VGGish model\n",
    "def extract_vggish_features(audio_path, vggish_model):\n",
    "    audio = preprocess_audio(audio_path)\n",
    "    # Convert the audio to a tensor with the correct shape for VGGish\n",
    "    audio_input = tf.convert_to_tensor(audio, dtype=tf.float32)\n",
    "    audio_input = tf.expand_dims(audio_input, 0)  # Add batch dimension\n",
    "    # Pass through VGGish model\n",
    "    features = vggish_model(audio_input)\n",
    "    return features\n",
    "\n",
    "\n",
    "vggish_model = load_vggish_model()\n",
    "audio_path = 'Extracted Audio' \n",
    "vggish_features = extract_vggish_features(audio_path, vggish_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def residual_block(x, dilation_rate):\n",
    "    conv = layers.Conv1D(filters=64, kernel_size=2, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "    conv = layers.Activation('relu')(conv)\n",
    "    conv = layers.Conv1D(filters=64, kernel_size=2, padding='causal')(conv)\n",
    "    \n",
    "    # Residual connection\n",
    "    x = layers.add([x, conv])\n",
    "    return x\n",
    "\n",
    "def create_wavenet_model(input_shape=(16000, 1), num_classes=10):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv1D(filters=64, kernel_size=2, padding='causal')(inputs)\n",
    "    \n",
    "    # Stack of residual blocks with increasing dilation rates\n",
    "    for dilation_rate in [1, 2, 4, 8, 16]:\n",
    "        x = residual_block(x, dilation_rate)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Extraction*\n",
    "1. Video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vgg16_features(video_frames):\n",
    "    vgg16_model = create_vgg16_model()\n",
    "    vgg16_features = vgg16_model.predict(video_frames)\n",
    "    return vgg16_features\n",
    "\n",
    "def extract_resnet50_features(video_frames):\n",
    "    resnet_model = create_resnet_model()\n",
    "    resnet_features = resnet_model.predict(video_frames)\n",
    "    return resnet_features\n",
    "\n",
    "def extract_c3d_features(video_frames):\n",
    "    c3d_model = create_c3d_model()\n",
    "    c3d_features = c3d_model.predict(video_frames)\n",
    "    return c3d_features\n",
    "\n",
    "def extract_tcn_features(mel_spectrogram):\n",
    "    tcn_model = create_tcn_model()\n",
    "    tcn_features = tcn_model.predict(mel_spectrogram)\n",
    "    return tcn_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_crnn_features(mel_spectrogram):\n",
    "    crnn_model = create_crnn_model()\n",
    "    crnn_features = crnn_model.predict(mel_spectrogram)\n",
    "    return crnn_features\n",
    "\n",
    "def extract_wavenet_features(audio_data):\n",
    "    wavenet_model = create_wavenet_model()\n",
    "    wavenet_features = wavenet_model.predict(audio_data)\n",
    "    return wavenet_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Fusion*\n",
    "1. Video \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "# Fuse video features\n",
    "def fuse_video_features(vgg16_features, resnet50_features, tcn_features, c3d_features):\n",
    "    return layers.Concatenate()([vgg16_features, resnet50_features, tcn_features, c3d_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "def fuse_audio_features(crnn_features, wav2vec_features, vggish_features, wavenet_features):\n",
    "    return layers.Concatenate()([crnn_features, wav2vec_features, vggish_features, wavenet_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Final Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model combining both video and audio\n",
    "def create_final_model(video_shape, audio_shape, num_classes=10):\n",
    "    tcn_model = create_tcn_model()\n",
    "    c3d_model = create_c3d_model()\n",
    "    vgg16_model = create_vgg16_model()\n",
    "    \n",
    "    wavenet_model = create_wavenet_model()\n",
    "    crnn_model = create_crnn_model()  \n",
    "    \n",
    "    \n",
    "    video_input = layers.Input(shape=video_shape)\n",
    "    audio_input = layers.Input(shape=audio_shape)\n",
    "\n",
    "    mel_spectrogram = extract_mel_spectrogram(audio_input, n_mels=128)\n",
    "\n",
    "    # Video Features\n",
    "    vgg16_features = extract_vgg16_features('Extracted Video')\n",
    "    resnet50_features = extract_resnet50_features('Extracted Video')\n",
    "    tcn_features = extract_tcn_features(mel_spectrogram)\n",
    "    c3d_features = extract_c3d_features('Extracted Video')\n",
    "    \n",
    "    # Audio Features\n",
    "    crnn_features =  extract_crnn_features(mel_spectrogram)\n",
    "    wavnet_features = extract_wavenet_features('Extracted Audio')\n",
    "\n",
    "    fused_video_features = fuse_video_features(vgg16_features, resnet50_features, tcn_features, c3d_features)\n",
    "    fused_audio_features = fuse_audio_features(crnn_features, wav2vec_features, vggish_features, wavnet_features)\n",
    "\n",
    "    combined_features = layers.Concatenate()([fused_video_features, fused_audio_features])\n",
    "\n",
    "    x = layers.Dense(256, activation='relu')(combined_features)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=[video_input, audio_input], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Compile and train the model (assuming data is preprocessed and ready)\n",
    "video_shape = (224, 224, 3)\n",
    "audio_shape = (16000, 1)\n",
    "num_classes = 10\n",
    "\n",
    "model = create_final_model(video_shape, audio_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the model:\n",
    "history = model.fit([X_train_video, X_train_audio], y_train, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the trained model\n",
    "model.save('final_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
